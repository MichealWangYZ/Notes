\documentclass[hyperref, UTF8, a4paper]{ctexart}

\usepackage{geometry}
\usepackage{titling}
\usepackage{titlesec}
\usepackage{paralist}
\usepackage{footnote}
\usepackage{enumerate}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{bbm}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{physics}
\usepackage{tikz}
\usepackage{autobreak}
\usepackage[ruled, vlined, linesnumbered, noend]{algorithm2e}
\usepackage[colorlinks, linkcolor=black, anchorcolor=black, citecolor=black]{hyperref}
\usepackage{prettyref}

% Page style
\geometry{left=3.18cm,right=3.18cm,top=2.54cm,bottom=2.54cm}
\titlespacing{\paragraph}{0pt}{1pt}{10pt}[20pt]
\setlength{\droptitle}{-5em}
\preauthor{\vspace{-10pt}\begin{center}}
\postauthor{\par\end{center}}

% Math operators
\DeclareMathOperator{\timeorder}{T}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\legpoly}{P}
\DeclareMathOperator{\primevalue}{P}
\DeclareMathOperator{\sgn}{sgn}
\newcommand*{\ii}{\mathrm{i}}
\newcommand*{\ee}{\mathrm{e}}
\newcommand*{\const}{\mathrm{const}}
\newcommand*{\comment}{\paragraph{注记}}
\newcommand*{\suchthat}{\quad \text{s.t.} \quad}
\newcommand*{\argmin}{\arg\min}
\newcommand*{\argmax}{\arg\max}
\newcommand*{\normalorder}[1]{: #1 :}
\newcommand*{\pair}[1]{\langle #1 \rangle}
\newcommand*{\fd}[1]{\mathcal{D} #1}
\DeclareMathOperator{\bigO}{\mathcal{O}}

% prettyref setting
\newrefformat{sec}{第\ref{#1}节}
\newrefformat{note}{注\ref{#1}}
\newrefformat{fig}{图\ref{#1}}
\newrefformat{alg}{算法\ref{#1}}
\renewcommand{\autoref}{\prettyref}

% TikZ setting
\usetikzlibrary{arrows,shapes,positioning}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{decorations.markings}
\tikzstyle arrowstyle=[scale=1]
\tikzstyle directed=[postaction={decorate,decoration={markings,
    mark=at position .5 with {\arrow[arrowstyle]{stealth}}}}]
\tikzstyle ray=[directed, thick]
\tikzstyle dot=[anchor=base,fill,circle,inner sep=1pt]

% Algorithm setting
\renewcommand{\algorithmcfname}{算法}
% Python-style code
\SetKwIF{If}{ElseIf}{Else}{if}{:}{elif:}{else:}{}
\SetKwFor{For}{for}{:}{}
\SetKwFor{While}{while}{:}{}
\SetKwInput{KwData}{输入}
\SetKwInput{KwResult}{输出}
\SetArgSty{textnormal}

\renewcommand{\emph}[1]{\textbf{#1}}
\newcommand*{\concept}[1]{\underline{\textbf{#1}}}

\title{统计推断}
\author{吴何友}

\begin{document}

\maketitle

\section{统计推断的基本概念}

我们常常需要面对这样的问题：设有一个在我们关心的范围内不随时间变化的随机变量（称为\concept{总体}）$\mathcal{X}$，我们并不完全知道这个随机变量的形式。
现在我们获知了和$\mathcal{X}$有关的一系列事件$X$（称为\concept{证据}），要通过它们来推知关于$\mathcal{X}$的一些信息，这个过程就是\concept{统计推断}。
例如，证据可以是反复运行$\mathcal{X}$而获得的一组取值
\begin{equation}
    \mathcal{D} = \{X_i\},
\end{equation}
这称为\concept{样本}，获得取值的方式称为\concept{采样}）。

\subsection{常见的统计推断任务}

常见的统计推断任务包括
\begin{itemize}
    \item \concept{假设检验}，即从一系列证据出发，判断是否应该认为关于$\mathcal{X}$的某个命题成立；
    \item \concept{概率估计}，即判断某个命题为真的概率有多大，这和假设检验有非常显然的联系；
    \item \concept{参数估计}，即判断与总体相关的一些参数的取值（或者取值的概率分布）；
    \item \concept{相关性分析}，这是在$\mathcal{X}$有多个分量时使用的，即分析这些变量之间的关系；
    \item \concept{机器学习}，即从较大的样本中将数据分类贴上标签；
\end{itemize}
还有许许多多其它的任务。

机器学习的一个特殊的例子是
\begin{equation}
    \mathcal{X} = (\vb{x}, y),
\end{equation}
$\vb{x}$是一组数据（通常称为\concept{特征}），$y$是和这组数据有关的另一个数据（通常称为\concept{标签}），此时的统计推断就是\concept{监督学习}。
如果直接从样本分析$P(\vb{x}, y)$的特征，就是\concept{生成模型}，而如果从样本分析$P(y|\vb{x})$的特征，那就是\concept{判别模型}。两者之间有着这样的关系：
\begin{equation}
    P(y | \vb{x}) = \frac{P(\vb{x}, y)}{P(\vb{x})} = \frac{P(\vb{x}, y)}{\sum_{y'} P(\vb{x}, y')}, 
\end{equation}
这里使用的记号需要特殊说明一下：$P(y | \vb{x})$实际上是“在某次运行$\mathcal{X}$，得到的特征是$\vb{x}$的条件下，发现其标签为$y$”的概率的简写，$P(\vb{x}, y)$同理。
为了简洁我们接下来在不至于混淆时不强调“随机变量”和“随机变量的可能取值”的区别。                                                
\subsection{模型}

当然，既然$\mathcal{X}$是自然界中一系列随机性过程给出的输出，我们总是可以找到一系列数目往往非常大的随机变量$\alpha_1, \alpha_2, \ldots, \alpha_N$，它们决定了$\mathcal{X}$，即
\[
    \mathcal{X} = F(\alpha_1, \alpha_2, \ldots, \alpha_N).
\]
我们可以把物理定律当成某种“计算过程”，向它输入一些事件，就可以输出一个$\mathcal{X}$的值。
我们当然不可能使用如此大量的随机变量来描述$\mathcal{X}$，即使技术上可行，这也没有提供给我们任何有价值的信息，因为这相当于做了一次虚拟仿真实验。
但，如果我们能够找到某个事件$H$和一个随机变量$\theta$（它可能也含有大量的分量，但无论如何比$\{\alpha\}$简洁），使得
\[
    P(\mathcal{X} = C | H, \theta) = f(C ; \theta), 
\]
且$P(H)$非常大，那就可以大大简化我们要处理的问题，并且提供给我们一个“因为所以”式的\emph{解释}——因为$\theta$取了某些值，所以$\mathcal{X}$取了这个特定的值。
我们称$H$为\concept{模型假设}，$f(\mathcal{X};\theta)$为\concept{模型}，$\theta$为\concept{参数}。
在$P(H)$非常大（以至于可以认为$H$是确凿无疑的一个命题）时，我们就有
\begin{equation}
    P(\mathcal{X} = C | \theta) = f(C ; \theta).
\end{equation}
模型假设是否正确可以通过假设检验来判断，也可以通过专家知识给出。

\subsection{主观概率}

当然，由于$\mathcal{X}$是通过一个实际的随机过程产生的，我们肯定会有一个“真实的”概率$P(\mathcal{X}=C)$，并进而可以计算出各种不同的事件发生的真实概率。
但大部分时候，我们都不能够把产生$\mathcal{X}$的物理过程写下来，而只是有一些零散的证据而已，此时讨论真实概率是怎样的根本就毫无意义。

我们采取贝叶斯学派的观点，即将对命题的置信程度当成一种概率测度（它多半和真实概率不一样），称为\concept{主观概率}，并使用$p(\cdot)$表示。
证据的出现当然会导致对各种命题的置信程度的变化。贝叶斯学派做了以下假定：如果事件$A$实际上发生了（或者说事件$A$是证据的一部分），那么要做以下\concept{概率更新}：
\begin{equation}
    p(B) \longleftarrow p(B|A),
\end{equation}
即事件$A$出现之后，应该将$B$发生的概率（即对$B$的置信程度）替换为$A$发生之前的条件概率。
通过这样的方式定义的主观概率就是\concept{贝叶斯概率}。
出于显而易见的原因，我们称$p(B)$为\concept{先验概率}，称$p(B|A)$为\concept{后验概率}；概率更新让上一轮概率更新的后验概率变成本轮概率更新的先验概率。

有定理（convergence-to-truth theorems）保证只要有足够多的证据，总是可以让贝叶斯概率收敛到真实概率上。
因此贝叶斯方法总是可以用的。
另一个选择贝叶斯方法的原因是，它可以很好地表述“过往的证据给我们留下的知识”。
概率更新肯定要有一个起点，在起点处不同事件的概率被赋予一个初始值，只需要把这个初始值（也就是整个更新过程的先验概率）选取为以前的概率更新的结果就可以了。

总之，贝叶斯概率更新的步骤如下：

\begin{algorithm}[H]

    \DontPrintSemicolon
    \SetAlgoLined

    \KwData{本次概率更新的先验概率$p_0(B)$，证据集$\{X_i\}$，证据$X$的先验概率$p_0(X)$，$B$成立时每个证据的条件概率}
    \KwResult{更新结束后的贝叶斯概率$p_\text{final}(B)$}
    
    $p(B) \leftarrow p_0(B)$ \;
    \For{每一个$X_i$}{
        计算证据$X_i$出现的先验概率$p(X_i) = p_0(X_i)$ \;
        计算后验概率$p(B|X_i) = \frac{p(B)}{p(X)} p(X_i | B)$ \;
        概率更新：$p(B) \leftarrow p(B|X_i)$ \;
    }
    \Return{$p(B)$}\;

    \caption{贝叶斯更新}
    \label{alg:bayesian-updating}
\end{algorithm}

\section{贝叶斯推断任务}

\subsection{模型选择}

\section{频率学派}

我们会注意到，大部分情况下贝叶斯推断都比频率学派的推断更为费力，这是因为频率学派实际上做了相当多非常强的假设。

\end{document}