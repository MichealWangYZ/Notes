\documentclass[UTF8, a4paper]{ctexart}

\usepackage{geometry}
\usepackage{titling}
\usepackage{titlesec}
\usepackage{paralist}
\usepackage{footnote}
\usepackage{enumerate}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{physics}
\usepackage[colorlinks, linkcolor=black, anchorcolor=black, citecolor=black]{hyperref}

\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\titlespacing{\paragraph}{0pt}{1pt}{10pt}[20pt]
\setlength{\droptitle}{-5em}
\preauthor{\vspace{-10pt}\begin{center}}
\postauthor{\par\end{center}}

\newcommand*{\natnums}{\mathbb{N}}
\newcommand*{\integers}{\mathbb{Z}}
\newcommand*{\reals}{\mathbb{R}}

\newcommand*{\diff}{\mathop{}\!\mathrm{d}}
\newcommand*{\st}{\quad \text{s.t.} \quad}
\newcommand*{\const}{\mathrm{const}}
\DeclareMathOperator{\exception}{\mathbb{E}}

% \renewenvironment{itemize}{\begin{compactitem}}{\end{compactitem}}
% \renewenvironment{enumerate}{\begin{compactenum}}{\end{compactenum}}

\newenvironment{bigcase}{\left\{\quad\begin{aligned}}{\end{aligned}\right.}

\title{信息论}
\author{吴何友}

\begin{document}

\maketitle

符号规定：以下如无特殊说明，$\log$以$2$为底。这是不重要的，实际上完全可以使用别的底。

\section{随机变量的复杂度和熵}

设有离散型随机变量$X \sim p(x)$。我们需要衡量这个随机变量携带的信息量，或者说，这个随机变量的值如果能够确定，我们可以收到多少信息。
所谓信息，就是不确定性的消除，因此我们只需要衡量这个随机变量有多混乱，就衡量了它能够提供的信息。
这种混乱程度称为\textbf{信息熵}，它是随机变量$X$的不同取值的概率的函数，即
\[
    H = S(p_1, p_2, \ldots).
\]
我们要求信息熵满足以下条件：
\begin{enumerate}
    \item 连续性，即$S$对各个$p_i$都是连续的；
    \item 在等概率时，即如果$X$有$N$个取值，每个取值的概率是$1/N$时，$N$越大$S$越大（这是很合理的，因为涉及越长的编码的随机变量携带的信息显然越多）；
    \item 可加性，即
    \begin{equation}
        H(p_1, p_2, \ldots, p_m) = 
    \end{equation}
\end{enumerate}
满足以上条件的唯一一个定义就是
\begin{equation}
    H(X) = - \sum_{\text{possible } x} p(x) \log p(x).
\end{equation}
这样就得到了信息熵的表达式。
设$X$是$N$个取值的等概率分布的随机变量，那么就有
\begin{equation}
    H(X) = \log N,
\end{equation}
因此信息熵可以看成随机变量$X$的等效

\end{document}