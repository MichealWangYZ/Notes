\documentclass[hyperref, UTF8, a4paper]{ctexart}

\usepackage{geometry}
\usepackage{titling}
\usepackage{titlesec}
\usepackage{paralist}
\usepackage{footnote}
\usepackage{enumerate}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{bbm}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{physics}
\usepackage{tikz}
\usepackage[ruled, vlined, linesnumbered, noend]{algorithm2e}
\usepackage[colorlinks, linkcolor=black, anchorcolor=black, citecolor=black]{hyperref}
\usepackage{prettyref}

% Page style
\geometry{left=3.18cm,right=3.18cm,top=2.54cm,bottom=2.54cm}
\titlespacing{\paragraph}{0pt}{1pt}{10pt}[20pt]
\setlength{\droptitle}{-5em}
\preauthor{\vspace{-10pt}\begin{center}}
\postauthor{\par\end{center}}

% Math operators
\DeclareMathOperator{\timeorder}{T}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\legpoly}{P}
\DeclareMathOperator{\primevalue}{P}
\DeclareMathOperator{\sgn}{sgn}
\newcommand*{\ii}{\mathrm{i}}
\newcommand*{\ee}{\mathrm{e}}
\newcommand*{\const}{\mathrm{const}}
\newcommand*{\comment}{\paragraph{注记}}
\newcommand*{\suchthat}{\quad \text{s.t.} \quad}
\newcommand*{\argmin}{\arg\min}
\newcommand*{\argmax}{\arg\max}
\newcommand*{\normalorder}[1]{: #1 :}
\newcommand*{\pair}[1]{\langle #1 \rangle}
\newcommand*{\fd}[1]{\mathcal{D} #1}
\newcommand*{\bigO}{\mathcal{O}}

% prettyref setting
\newrefformat{sec}{第\ref{#1}节}
\newrefformat{note}{注\ref{#1}}
\newrefformat{fig}{图\ref{#1}}
\newrefformat{alg}{算法\ref{#1}}
\renewcommand{\autoref}{\prettyref}

% TikZ setting
\usetikzlibrary{arrows,shapes,positioning}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{decorations.markings}
\tikzstyle arrowstyle=[scale=1]
\tikzstyle directed=[postaction={decorate,decoration={markings,
    mark=at position .5 with {\arrow[arrowstyle]{stealth}}}}]
\tikzstyle ray=[directed, thick]
\tikzstyle dot=[anchor=base,fill,circle,inner sep=1pt]

% Algorithm setting
\renewcommand{\algorithmcfname}{算法}
% Python-style code
\SetKwIF{If}{ElseIf}{Else}{if}{:}{elif:}{else:}{}
\SetKwFor{For}{for}{:}{}
\SetKwFor{While}{while}{:}{}
\SetKwInput{KwData}{输入}
\SetKwInput{KwResult}{输出}
\SetArgSty{textnormal}

\title{蒙特卡罗方法}
\author{吴何友}

\begin{document}

\maketitle

\section{经典蒙特卡洛方法}

\subsection{马尔科夫链蒙特卡洛方法}\label{sec:mcmc-method}

平衡态统计物理的核心问题就是计算配分函数
\begin{equation}
    Z = \sum_\mathcal{C} \ee^{-\beta H[\mathcal{C}]} = \sum_\mathcal{C} W(\mathcal{C}).
    \label{eq:partition-function}
\end{equation}
这里我们用$\mathcal{C}$表示一个任意的系统能量本征态，经典情况下这就是一个系统构型，量子情况下还需要对哈密顿量做一个对角化。
本节将主要讨论经典系统，因为它不涉及通常难以计算的算符对角化，并且实际上很多时候量子系统可以化归为经典系统。
如果能够将每个$\mathcal{C}$对应的$W[\mathcal{C}]$算出来那还可以大大简化期望值的计算。

显然，涉及系统构型的路径积分\eqref{eq:partition-function}是非常难以计算的。
一种近似方法是\textbf{马尔科夫链蒙特卡洛法（MCMC）}，即构造一个各态遍历、不可约的马尔可夫链
\[
    \cdots \longrightarrow \mathcal{C}_{i-1} \longrightarrow \mathcal{C}_i \longrightarrow \mathcal{C}_{i+1} \longrightarrow \cdots,
\]
使得
\begin{equation}
    \frac{p(\mathcal{C} \rightarrow \mathcal{D})}{p(\mathcal{D} \rightarrow \mathcal{C})} = \frac{W(\mathcal{D})}{W(\mathcal{C})} = \ee^{-\beta(H[\mathcal{D}]-H[\mathcal{C}])},
    \label{eq:markov-mcmc}
\end{equation}
则达到平衡时必定有细致平衡条件
\[
    p(\mathcal{C}) p(\mathcal{C} \rightarrow \mathcal{D}) = p(\mathcal{D}) p(\mathcal{D} \rightarrow \mathcal{C}),
\]
就有
\[
    \frac{W(\mathcal{D})}{W(\mathcal{C})} = \frac{p(\mathcal{D})}{p(\mathcal{C})}.
\]
专门使用$\pi(\mathcal{C})$来表示平衡态概率，即有
\begin{equation}
    \frac{W(\mathcal{D})}{W(\mathcal{C})} = \frac{\pi(\mathcal{D})}{\pi(\mathcal{C})}.
\end{equation}
这样我们只需要让这个马尔可夫链计算到收敛（有限、时不变、不可约、非循环的马尔科夫链肯定可以收敛，而由于可以找到一个$p(\mathcal{C})$的安排让细致平衡条件成立，总是可以收敛到$W(\mathcal{C})/Z$），
此时按照系综平均等于时间平均的原理，任何一个物理量的期望值就是
\begin{equation}
    \expval{O} = \sum_{\mathcal{C}} \frac{W(\mathcal{C})}{Z} O[\mathcal{C}] = \frac{1}{N} \sum_i O[\mathcal{C}_i].
    \label{eq:classical-expectation}
\end{equation}
也即过程收敛之后（收敛之前的过程称为\textbf{热化}，这一段数据并不是特别有用），只需要在时间序列$\{\mathcal{C}_i\}$上分别计算$O$的值，做时间平均，就得到了$O$的期望值。
需要注意的是实际上$N$不能取无穷大，因此我们希望平衡之后$\{\mathcal{C}_i\}$尽可能随机，即自相关要足够小。
马尔科夫链普遍具有这样的性质：由于每一时刻的状态只和前一时刻有关，后一时刻和前一时刻的分布不是独立的，但是随着时间推移，自相关会指数衰减，即
\begin{equation}
    A(\Delta t) \sim \ee^{- \Delta t / \tau}.
\end{equation}
如果我们需要抽取$N$个彼此统计无关的平衡态构型作为样本计算期望值，那么计算一个期望值的时间复杂度就是
\begin{equation}
    \bigO(t) \sim \bigO(\text{one step}) \cdot \tau \cdot N,
\end{equation}
因为两个不相关的样本之间大约有$\tau$的时间。

因此问题的核心就是如何设计一个满足\eqref{eq:markov-mcmc}的不可约各态历经马尔可夫链。
这个过程未必要和实际的动力学过程完全一样，只要满足\eqref{eq:markov-mcmc}当然都可以。
不可约性相对来说是容易做到的，因此需要巧妙地设计$p(\mathcal{C} \rightarrow \mathcal{D})$，并且确认平衡后的$\{\mathcal{C}_i\}$在长时间上没有自相关。

\subsection{Metropolis-Hastings算法}

本节讨论一个能够达到\autoref{sec:mcmc-method}中要求的算法：Metropolis-Hastings算法，即\autoref{alg:metro-hast}。

\begin{algorithm}[H]

    \DontPrintSemicolon
    \SetAlgoLined

    \KwData{不同构型$\mathcal{C}$对应的$W[\mathcal{C}]$，计算步数$N$，一个容易抽样的分布$Q(\mathcal{C}' | \mathcal{C}_0)$}
    \KwResult{序列$\{\mathcal{C}_t\}$}
    
    选定一个初始状态$\mathcal{C}_0$\;
    $t=0$\;
    \While{$t<N$}{
        从分布$Q(\mathcal{C}' | \mathcal{C}_t)$中抽样出$\mathcal{C}'$，这个过程称为\textbf{提议} \;
        $A(\mathcal{C}' | \mathcal{C}_t) = \min(1, \frac{W(\mathcal{C}') Q(\mathcal{C}_t | \mathcal{C}')}{W(\mathcal{C}_t) Q(\mathcal{C}' | \mathcal{C}_t)})$\;
        从$[0,1]$的均匀分布抽样出$u$\;
        \eIf{$u \leq A(\mathcal{C}' | \mathcal{C}_t)$}{
            $\mathcal{C}_{t+1} = \mathcal{C}'$，这称为\textbf{接受}提议 \;
        }{
            $\mathcal{C}_{t+1} = \mathcal{C}_t$，这称为\textbf{拒绝}提议 \; 
        }
    }
    \Return{序列$\{\mathcal{C}_i\}$}\;

    \caption{Metropolis-Hastings算法}
    \label{alg:metro-hast}
\end{algorithm}

从\autoref{alg:metro-hast}中很容易看出，提议$\mathcal{C}'$被接受的概率为
\begin{equation}
    p(\mathcal{C} \to \mathcal{C}') = Q(\mathcal{C}' | \mathcal{C}) A(\mathcal{C}' | \mathcal{C}) = Q(\mathcal{C}' | \mathcal{C}) \min \left(1, \frac{W(\mathcal{C}') Q(\mathcal{C} | \mathcal{C}')}{W(\mathcal{C}) Q(\mathcal{C}' | \mathcal{C})} \right).
    \label{eq:prob-metro-hast}
\end{equation}
分类讨论可以发现\eqref{eq:markov-mcmc}的确是成立的。
只要我们保证$Q(\mathcal{C} | \mathcal{C}')$描述的马尔可夫链是不可约的，那么\eqref{eq:prob-metro-hast}描述的马尔可夫链就是不可约的，因为随意两个构型之间都能够跃迁。
因此，只要$Q(\mathcal{C} | \mathcal{C}')$描述的马尔可夫链不可约，Metropolis-Hastings算法一定是一个好的马尔可夫链蒙特卡洛方法。

虽然原则上$Q(\mathcal{C}' | \mathcal{C})$的选取不影响结果，但实际计算中不同的选择可以非常大地改变模拟的效率和质量。
例如，如果让$Q$比较大的$\mathcal{C}'$和$\mathcal{C}$几乎完全无关，那么$\mathcal{C}_t$很可能几乎总是在能量很大的构型附近徘徊，而不发生更新，从而算法需要特别长的时间才能真正收敛；甚至这可能让人误以为那些能量较高的构型已经收敛了。
因此通常采用局部更新的策略，即每次提议只尝试更动少数几个格点。

不过，局部更新的策略并不总是适用的。在临界点附近，有大量长程关联，局部更新是非常缓慢的，这称为\textbf{临界慢化}。
此时需要别的策略来做更新。

通常需要误差棒

\section{辅助场量子蒙特卡洛}

现在我们转而分析一个格点上的量子的平衡态统计系统。
特别讨论格点上的系统是因为这是固体物理中最为常见的模型，并且原则上，连续空间中的物理总是可以离散化为格点上的物理。
在路径积分表述中，量子的平衡态统计系统和经典的不同之处在于：
\begin{itemize}
    \item 配分函数的$\ee$指数上并不是简单的$\beta$乘以哈密顿量，而是哈密顿量加上一个$\pi \dot{\phi}$项以后对虚时间做积分，积分限为$0$到$\beta$。（在$\beta$很小——也即，在高温极限下——这个积分当然就等于哈密顿量乘以$\beta$）
    \item “每个格点上的粒子具有确定的状态”未必是能量本征态，换句话说偏好基未必是能量本征态。
\end{itemize}
由于这两个原因，计算每个系统构型（在这里以“每个格点上有某种状态的粒子”为表象）对应的未归一化概率$W(\mathcal{C})$是非常困难的。
因此我们不再僵化地使用\eqref{eq:classical-expectation}，而是转而通过
\begin{equation}
    \expval{O} = \frac{\trace(\hat{O} \ee^{-\beta \hat{H}})}{\trace \ee^{-\beta \hat{H}}}
    \label{eq:second-quantization-expectation}
\end{equation}
来计算期望。我们以“每个格点上的粒子状态”为表象，那么系统哈密顿量可以写成矩阵形式，至少原则上\eqref{eq:second-quantization-expectation}是可以用的。
我们照惯例做$\ee$指数的离散化：
\[
    \ee^{-\beta \hat{H}} = \prod_{i=1}^{\beta / \Delta t} \ee^{-\Delta \tau \hat{H}}.
\]
一般来说哈密顿量可以写成自由哈密顿量加上相互作用哈密顿量。本节仅讨论相互作用哈密顿量为四次型（即只有二体相互作用，这是合理的，因为基本上固体理论中的相互作用几乎总是来自库伦相互作用）的情况，即我们有
\begin{equation}
    \hat{H} = \hat{H}_0 + \hat{H}_I, \quad \hat{H}_I = - W \sum_{i} \left( \hat{O}^{(i)} \right)^2.
\end{equation}
这里我们假定已经将$\hat{H}_I$做了对角化，即在单粒子表象$\{\ket*{i}\}$下将它分解成一系列单粒子可观察量的平方之和。

\end{document}